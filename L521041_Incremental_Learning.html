
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Incremental Learning &#8212; incremental-learning</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Concept Drift" href="L194114_Concept_Drift.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">incremental-learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1 current">
  <a class="reference internal" href="#">
   Incremental Learning
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Concepts
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L194114_Concept_Drift.html">
   Concept Drift
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L589394_Jensen%E2%80%93Shannon_divergence.html">
   Jensen–Shannon divergence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L241645_A_spectrum_of_model_freshness.html">
   A spectrum of model freshness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L883094_Incremental_Learning_in_Computer_Vision.html">
   Incremental Learning in Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L369117_Incremental_Learning_in_Recommender_Systems.html">
   Incremental Learning in Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L725007_River.html">
   River
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L595800_Lambda_Learner.html">
   Lambda Learner
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L305905_Scikit_warm_start.html">
   Scikit warm-start
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L498804_GLMix.html">
   GLMix
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L832818_IncCTR.html">
   IncCTR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L753817_SML.html">
   SML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L395827_CIGC.html">
   CIGC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L958254_GraphSAIL.html">
   GraphSAIL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L926913_NMRN.html">
   NMRN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L766388_RKMF.html">
   RKMF
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/L521041_Incremental_Learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/incremental-learning/main?urlpath=tree/docs/L521041_Incremental_Learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sparsh-ai/incremental-learning/blob/main/docs/L521041_Incremental_Learning.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-considerations">
   Key considerations
  </a>
  <ul class="nav section-nav flex-column">
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="incremental-learning">
<h1>Incremental Learning<a class="headerlink" href="#incremental-learning" title="Permalink to this headline">¶</a></h1>
<p>Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference.</p>
<p>The extent to which a system must be plastic in order to integrate novel information and stable in order not to catastrophically interfere with consolidated knowledge is known as the stability-plasticity dilemma and has been widely studied in both biological systems and computational models (Ditzler et al. 2015, Mermillod et al. 2013, Grossberg 1980, 2012). Due to the very challenging but high-impact aspects of lifelong learning, a large body of computational approaches have been proposed that take inspiration from the biological factors of learning from the mammalian brain.</p>
<p>Plasticity is an essential feature of the brain for neural malleability at the level of cells and circuits (see Power &amp; Schlaggar (2016) a survey). For a stable continuous lifelong process, two types of plasticity are required: (i) Hebbian plasticity (Hebb 1949) for positive feedback instability, and (ii) compensatory homeostatic plasticity which stabilizes neural activity. It has been observed experimentally that specialized mechanisms protect knowledge about previously learned tasks from interference encountered during the learning of novel tasks by decreasing rates of synaptic plasticity (Cichon &amp; Gan 2015). Together, Hebbian learning and homeostatic plasticity stabilize neural circuits to shape optimal patterns of experience-driven connectivity, integration, and functionality (Zenke, Gerstner &amp; Ganguli 2017, Abraham &amp; Robins 2005).</p>
<p>Neurosynaptic plasticity is an essential feature of the brain yielding physical changes in the neural structure and allowing us to learn, remember, and adapt to dynamic environments (see Power &amp; Schlaggar (2016) for a survey). The brain is particularly plastic during critical periods of early development in which neural networks acquire their overarching structure driven by sensorimotor experiences. Plasticity becomes less prominent as the biological system stabilizes through a well-specified set of developmental stages, preserving a certain degree of plasticity for its adaptation and reorganization at smaller scales (Hensch et al. 1998, Quadrato et al. 2014, Kiyota 2017). The specific profiles of plasticity during critical and post-developmental periods vary across biological systems (Uylings 2006), showing a consistent tendency to decreasing levels of plasticity with increasing age (Hensch 2004). Plasticity plays a crucial role in the emergence of sensorimotor behaviour by complementing genetic information which provides a specific evolutionary path (Grossberg 2012). Genes or molecular gradients drive the initial development for granting a rudimentary level of performance from the start whereas extrinsic factors such as sensory experience complete this process for achieving higher structural complexity and performance (Hirsch &amp; Spinelli 1970, Shatz 1996, Sur &amp; Leamey 2001).</p>
<p><center><figure><img src='_images/L521041_1.png'><figcaption>Schematic view of two aspects of neurosynaptic adaptation: a) Hebbian learning with homeostatic plasticity as a compensatory mechanism that uses observations to compute a feedback control signal (Adapted with permission from Zenke, Gerstner & Ganguli (2017)). b) The complementary learning systems (CLS) theory (McClelland et al. 1995) comprising the hippocampus for the fast learning of episodic information and the neocortex for the slow learning of structured knowledge.</figcaption></figure></center></p>
<p>Additional interference effects were observed for long-term knowledge. Pallier et al. (2003) studied the word recognition abilities of Korean-born adults whose language environment shifted completely from Korean to French after being adopted between the ages of 3 and 8 by French families. Behavioural tests showed that subjects had no residual knowledge of the previously learned Korean vocabulary. Functional brain imaging data showed that the response of these subjects while listening to Korean was no different from the response while listening to other foreign languages that they had been exposed to, suggesting that their previous knowledge of Korean was completely overwritten. Interestingly, brain activations showed that Korean-born subjects produced weaker responses to French with respect to native French speakers. It was hypothesized that, while the adopted subjects did not show strong responses to transient exposures to the Korean vocabulary, prior knowledge of Korean may have had an impact during the formulation of language skills to facilitate the reacquisition of the Korean language should the individuals be re-exposed to it in an immersive way.</p>
<p>Artificial agents which evolve in dynamic environments should be able to update their capabilities in order to integrate new data. Depending on the work hypotheses made, names such as continual learning, lifelong learning or incremental learning (IL) are used to describe associated works. The challenge faced in all cases is catastrophic forgetting, i.e., the tendency of a neural network to underfit past data when new ones are ingested. The effect of catastrophic forgetting is alleviated either by increasing the model capacity to accommodate new knowledge or by storing exemplars of past classes in a bounded memory and replaying them in each new state.</p>
<p>Human beings learn by building on their memories and applying past knowledge to understand new concepts. Unlike humans, existing neural networks (NNs) mostly learn in isolation and can be used effectively only for a limited time. Models become less accurate over time, for instance, due to the changing distribution of data – the phenomenon known as concept drift (Schlimmer and Granger, 1986; Widmer and Kubat, 1993).</p>
<p>Humans do not typically exhibit strong events of catastrophic forgetting because the kind of experiences we are exposed to are very often interleaved (Seidenberg &amp; Zevin 2006). Nevertheless, forgetting effects may be observed when new experiences are strongly immersive such as in the case of children drastically shifting from Korean to French. Together, these findings reveal a well-regulated balance in which, on the one hand, consolidated knowledge must be protected to ensure its long-term durability and avoid catastrophic interference during the learning of novel tasks and skills over long periods of time. On the other hand, under certain circumstances such as immersive long-term experiences, old knowledge can be overwritten in favour of the acquisition and refinement of new knowledge.</p>
<div class="tip admonition">
<p class="admonition-title">Note</p>
<p>Catastrophic forgetting is the tendency of neural networks to underfit past data when new ones are ingested.</p>
</div>
<p>Throughout the years, numerous methods have been proposed to address the challenge known as catastrophic forgetting (CF) or catastrophic interference (McCloskey and Cohen, 1989). Naive approaches to mitigate the problem, such as retraining the model from scratch to adapt to a new task (or a new data distribution), are costly and time-consuming. This is reinforced by the problems of capacity saturation and model expansion. Concretely, a parametric model, while learning data samples with different distributions or progressing through a sequence of tasks, eventually reaches a point at which no more knowledge can be stored – i.e. its representational capacity approaches the limit (Sodhani et al., 2020; Aljundi et al., 2019). At this point, either model’s capacity is expanded, or a selective forgetting – which likely incurs performance degradation – is applied. The latter choice may result either in a deterioration of prediction accuracy on new tasks (or data distributions) or forgetting the knowledge acquired before. This constraint is underpinned by a defining characteristic of Continuous Learning (CL), known as the stability-plasticity dilemma. Specifically, the phenomenon considers the model’s attempt to strike a balance between its stability (the ability to retain prior knowledge) and its plasticity (the ability to adapt to new knowledge).</p>
<p>There are certain desired properties (Desiderata of continual learning): 1) Knowledge retention - The model is not prone to catastrophic forgetting, 2) Forward transfer - The model learns a new task while reusing knowledge acquired from previous tasks, 3) Backward transfer - The model achieves improved performance on previous tasks after learning a new task, 4) Online learning - The model learns from a continuous data stream, 5) No task boundaries - The model learns without requiring neither clear task nor data boundaries, 6) Fixed model capacity - Memory size is constant regardless of the number of tasks and the length of a data stream.</p>
<p>Intuitively, the historical interactions provide more evidence on user long-term (e.g., inherent) interest and the newly collected interactions are more reflective of user short-term preference. Three retraining strategies are most widely adopted, depending on the data utilization: 1) Fine-tuning, which updates the model based on the new interactions only. This way is memory and time efficient, since only new data is to be handled. However, it ignores the historical data that contains long-term preference signal, thus can easily cause overfitting and forgetting issues, 2) Sample-based retraining, which samples historical interactions and adds them to new interactions to form the training data. The sampled interactions are expected to retain long-term preference signal, which need be carefully selected to obtain representative interactions. In terms of recommendation accuracy, it is usually worse than using all historical interactions due to the information loss caused by sampling, and 3) Full retraining, which trains the model on the whole data that includes all historical and new interactions. Undoubtedly, this method costs most resources and training time, but it provides the highest model fidelity since all available interactions are utilized.</p>
<p>Although full model retraining provides the highest fidelity, it is not necessary to do so. The key reason is that the historical interactions have been trained in the previous training, which means the model has already distilled the “knowledge” from the historical data. If there is a way to retain the knowledge well and transfer it to the training on new interactions, we should be able to keep the same performance level as the full retraining, even though we do not use the historical data during model retraining. Furthermore, if the knowledge transfer is “smart” enough to capture more patterns like recent data is more reflective of near future performance, we even have the opportunity to improve over the full retraining in recommendation accuracy.</p>
<div class="tip admonition">
<p class="admonition-title">Note</p>
<p>Different name, same thing: <em>Online learning, Incremental learning, Sequential learning, Iterative learning, Continuous learning, Out-of-core learning.</em></p>
</div>
<p>Classic machine learning algorithms are mostly based on batch learning, i.e., the model is trained on a fixed dataset, then deployed for online inference. The assumption is that one can afford to wait until the data is accumulated before a new model is trained. This paradigm does not apply well to data streams where the model needs to be updated before a full dataset is available. Incremental learning fills the gap by learning from the few newly available samples without resorting to a full training. Similar concepts such as online learning, continual learning (Gepperth and Hammer, 2016; Parisi et al., 2019; Delange et al., 2021) appear in different contexts in the literature.</p>
<p>In order to keep up with the latest trend, it is tempting to take the last trained model as an initial start point, then continue to train it on the latest dataset, known as <strong>warm start</strong>. However, the model tends to overfit on the new dataset and forget what has been learned so far. This phenomenon is often referred to as catastrophic forgetting (Goodfellow et al., 2013). This problem can be mitigated if we train models on both the past and the latest datasets. This however results in the ever growing training time which conflicts with the goal of a fast model refreshing rate.</p>
<p><center><img src='_images/L521041_2.png'></center></p>
<p>Suppose there is a stream of datasets <span class="math notranslate nohighlight">\(\{D_0, D_1, ...\}\)</span> indexed by time. At time t, we have access to  <span class="math notranslate nohighlight">\(D_0^t = \{D_0, D_1, ..., D_t\}\)</span>. Our goal is to build a model based on the stream. As illustrated in the above figure, one approach is to train the model on the entire history <span class="math notranslate nohighlight">\(D_0^t\)</span>. The training datasets quickly grow overwhelmingly large. To constrain the training dataset size, we can place a fixed length sliding window on the stream, only the datasets inside the window are used for training as in the above figure. For example, if at time <span class="math notranslate nohighlight">\(t\)</span> we choose window size <span class="math notranslate nohighlight">\(l\)</span> to train the model, we are using <span class="math notranslate nohighlight">\(D_{t−l+1}^t = {D_{t−l+1}, D_{t−l+2}, ..., D_t}\)</span>. This approach retrains the entire model even if there is only one more new dataset, which does not scale well with a large window length. Another approach is to use a small window length for retraining but initialize the model coefficients based on the model trained previously. For example, we set <span class="math notranslate nohighlight">\(l\)</span> = 1 and use the model at <span class="math notranslate nohighlight">\(t − 1\)</span> to initialize the model training at time <span class="math notranslate nohighlight">\(t\)</span>. This approach, named as warm start, can improve the training efficiency but may result in a model that forgets what is learned in the past.</p>
<p>We can use <strong>incremental learning</strong> approach to address both aspects of the model training. (1) Model training speed: since we only need to train on the incremental portion of data, faster training speed is achieved; (2) Model quality: key quantities from the previous training are used to construct an informative prior, so the model remembers the essential information from the past data and learn new information from the latest training data.</p>
<p>We observe performance degradation when the recommendation model stops updating in a mainstream recommendation service which may lead to significant loss of revenue and a poor user experience. However, directly retraining the model using only the recent records often causes a catastrophic forgetting problem, with the model losing track of the key user information needed to capture long term preferences. <strong>Incremental learning</strong> provides one direction for tackling this problem. Incremental learning uses the most recent data to update the current model, but is designed to prevent substantial forgetting. This significantly improves training efficiency without extra computational resource and meanwhile prevents model performance degradation.</p>
<p>There are three main lines of work for incremental learning: experience replay (reservoir), parameter isolation and regularization based methods. Reservoir methods use an additional data reservoir to store the most representative historical data and replay it while learning new tasks to alleviate forgetting. Parameter isolation trains distinct models for different tasks, but leads to continual growth of the model size which is not favourable for training large-scale systems. Regularization based approaches aim to consolidate previous knowledge by introducing regularization terms in the loss when learning on new data.</p>
<div class="section" id="key-considerations">
<h2>Key considerations<a class="headerlink" href="#key-considerations" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>When should a model be retrained? - Periodic training, Performance-based trigger, Trigger based on Data changes, Retraining on demand.</p></li>
<li><p>How much data is needed for retraining? - Fixed window, Dynamic window, Representative Subsample selection.</p></li>
<li><p>What should be retrained? - Continual learning vs Transfer learning, Offline(batch) Vs Online(Incremental).</p></li>
<li><p>When to deploy your model after retraining? - A/B testing.</p></li>
</ol>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="L194114_Concept_Drift.html">Concept Drift</a></li>
<li class="toctree-l1"><a class="reference internal" href="L589394_Jensen%E2%80%93Shannon_divergence.html">Jensen–Shannon divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="L241645_A_spectrum_of_model_freshness.html">A spectrum of model freshness</a></li>
<li class="toctree-l1"><a class="reference internal" href="L883094_Incremental_Learning_in_Computer_Vision.html">Incremental Learning in Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="L369117_Incremental_Learning_in_Recommender_Systems.html">Incremental Learning in Recommender Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="L725007_River.html">River</a></li>
<li class="toctree-l1"><a class="reference internal" href="L595800_Lambda_Learner.html">Lambda Learner</a></li>
<li class="toctree-l1"><a class="reference internal" href="L305905_Scikit_warm_start.html">Scikit warm-start</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="L498804_GLMix.html">GLMix</a></li>
<li class="toctree-l1"><a class="reference internal" href="L832818_IncCTR.html">IncCTR</a></li>
<li class="toctree-l1"><a class="reference internal" href="L753817_SML.html">SML</a></li>
<li class="toctree-l1"><a class="reference internal" href="L395827_CIGC.html">CIGC</a></li>
<li class="toctree-l1"><a class="reference internal" href="L958254_GraphSAIL.html">GraphSAIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="L926913_NMRN.html">NMRN</a></li>
<li class="toctree-l1"><a class="reference internal" href="L766388_RKMF.html">RKMF</a></li>
</ul>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>How to Retrain Recommender System? A Sequential Meta-Learning Method. Yang Zhang, Fuli Feng, Chenxu Wang, Xiangnan He, Meng Wang, Yan Li, Yongdong Zhang. 2020. arXiv. <a class="reference external" href="https://arxiv.org/abs/2005.13258">https://arxiv.org/abs/2005.13258</a></p></li>
<li><p>Lambda Learner: Fast Incremental Learning on Data Streams. Rohan Ramanath, Konstantin Salomatin, Jeffrey D. Gee, Kirill Talanine, Onkar Dalal, Gungor Polatkan, Sara Smoot, Deepak Kumar. 2020. arXiv. <a class="reference external" href="https://arxiv.org/abs/2010.05154">https://arxiv.org/abs/2010.05154</a></p></li>
<li><p>Online-Updating Regularized Kernel Matrix Factorization Models for Large-Scale Recommender Systems. Steffen Rendle, Lars Schmidt-Thieme. 2008. RecSys. <a class="reference external" href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.8010&amp;rep=rep1&amp;type=pdf">https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.8010&amp;rep=rep1&amp;type=pdf</a></p></li>
<li><p>Neural Memory Streaming Recommender Networks with Adversarial Training. Wang et. al.. 2018. KDD. <a class="reference external" href="https://www.kdd.org/kdd2018/accepted-papers/view/neural-memory-streaming-recommender-networks-with-adversarial-training">https://www.kdd.org/kdd2018/accepted-papers/view/neural-memory-streaming-recommender-networks-with-adversarial-training</a></p></li>
<li><p>Causal Incremental Graph Convolution for Recommender System Retraining. Sihao Ding, Fuli Feng, Xiangnan He, Yong Liao, Jun Shi, Yongdong Zhang. 2021. arXiv. <a class="reference external" href="https://arxiv.org/abs/2108.06889v1">https://arxiv.org/abs/2108.06889v1</a></p></li>
<li><p>GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems. Yishi Xu, Yingxue Zhang, Wei Guo, Huifeng Guo, Ruiming Tang, Mark Coates. 2020. arXiv. <a class="reference external" href="https://arxiv.org/abs/2008.13517">https://arxiv.org/abs/2008.13517</a></p></li>
<li><p>Incremental Learning for Personalized Recommender Systems. Yunbo Ouyang, Jun Shi, Haichao Wei, Huiji Gao. 2021. arXiv. <a class="reference external" href="https://arxiv.org/abs/2108.13299">https://arxiv.org/abs/2108.13299</a></p></li>
<li><p>A Practical Incremental Method to Train Deep CTR Models. Yichao Wang, Huifeng Guo, Ruiming Tang, Zhirong Liu, Xiuqiang He. 2020. arXiv. <a class="reference external" href="https://arxiv.org/abs/2009.02147">https://arxiv.org/abs/2009.02147</a></p></li>
<li><p>Creme. Max Halford. 2019.  <a class="reference external" href="https://maxhalford.github.io/slides/creme-pydata">https://maxhalford.github.io/slides/creme-pydata</a></p></li>
<li><p>Continual Lifelong Learning in Natural Language Processing: A Survey. Magdalena Biesialska, Katarzyna Biesialska, Marta R. Costa-jussà. 2020. arXiv. <a class="reference external" href="https://aclanthology.org/2020.coling-main.574/">https://aclanthology.org/2020.coling-main.574/</a></p></li>
<li><p>Online Continual Learning in Image Classification: An Empirical Survey. Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, Scott Sanner. 2021. arXiv. <a class="reference external" href="https://arxiv.org/abs/2101.10423">https://arxiv.org/abs/2101.10423</a></p></li>
<li><p>Class-incremental learning: survey and performance evaluation on image classification. Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel Menta, Andrew D. Bagdanov, Joost van de Weijer. 2020. arXiv. <a class="reference external" href="https://arxiv.org/abs/2010.15277">https://arxiv.org/abs/2010.15277</a></p></li>
<li><p>A Comprehensive Study of Class Incremental Learning Algorithms for Visual Tasks. Eden Belouadah, Adrian Popescu, Ioannis Kanellos. 2020. arXiv. <a class="reference external" href="https://arxiv.org/abs/2011.01844">https://arxiv.org/abs/2011.01844</a></p></li>
<li><p>Three scenarios for continual learning. Gido M. van de Ven, Andreas S. Tolias. 2019. arXiv. <a class="reference external" href="https://arxiv.org/abs/1904.07734v1">https://arxiv.org/abs/1904.07734v1</a></p></li>
<li><p>Continual Lifelong Learning with Neural Networks: A Review. German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, Stefan Wermter. 2018. arXiv. <a class="reference external" href="https://arxiv.org/abs/1802.07569">https://arxiv.org/abs/1802.07569</a></p></li>
<li><p>Retraining Model During Deployment: Continuous Training and Continuous Testing. Akinwande Komolafe. 2021.  <a class="reference external" href="https://neptune.ai/blog/retraining-model-during-deployment-continuous-training-continuous-testing">https://neptune.ai/blog/retraining-model-during-deployment-continuous-training-continuous-testing</a></p></li>
<li><p>To retrain, or not to retrain? Let’s get analytical about ML model updates.  2021.  <a class="reference external" href="https://evidentlyai.com/blog/retrain-or-not-retrain">https://evidentlyai.com/blog/retrain-or-not-retrain</a></p></li>
<li><p>Quickstart Guide to Automating Model Retraining. Luigi Patruno. 2019.  <a class="reference external" href="https://www.notion.so/c81d33b7db8b47eeb10b7a37797f8848">https://attachments.convertkitcdnn.com/114701/c81d33b7-db8b-47ee-b10b-7a37797f8848/quickstart_model_retraining.pdf</a></p></li>
<li><p>Common pitfalls in training and evaluating recommender systems. Hung-Hsuan Chen, Chu-An Chung, Hsin-Chien Huang, Wen Tsui. 2017. KDD. <a class="reference external" href="https://www.kdd.org/exploration_files/19-1-Article3.pdf">https://www.kdd.org/exploration_files/19-1-Article3.pdf</a></p></li>
<li><p>Fast Incremental Matrix Factorization for Recommendation with Positive-Only Feedback. Joao Vinagre, Alipio Mario Jorge, and Joao Gama. 2014. arXiv. <a class="reference external" href="https://asset-pdf.scinapse.io/prod/30495595/30495595.pdf">https://asset-pdf.scinapse.io/prod/30495595/30495595.pdf</a></p></li>
<li><p>GLMix: Generalized Linear Mixed Models For Large-Scale Response Prediction. Xianxing Zhang, Yitong Zhou, Yiming Ma, Bee-Chung Chen, Liang Zhang, Deepak Agarwal. 2016. KDD. <a class="reference external" href="https://www.kdd.org/kdd2016/papers/files/adf0562-zhangA.pdf">https://www.kdd.org/kdd2016/papers/files/adf0562-zhangA.pdf</a></p></li>
<li><p>Scikit-Multiflow: A Multi-output Streaming Framework. Jacob Montiel, Jesse Read, Albert Bifet, Talel Abdessalem. 2018. arXiv. <a class="reference external" href="https://arxiv.org/abs/1807.04662">https://arxiv.org/abs/1807.04662</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sparsh-ai/incremental-learning",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
     <div id="next">
        <a class="right-next" href="L194114_Concept_Drift.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Concept Drift</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>