{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8YkAA6ral_"
      },
      "source": [
        "# Avalanche Visual Incremental Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL9OJNlgp38o"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5Kf2GJtp06U"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/ContinualAI/avalanche.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gGo8L6Mp1c4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import SGD\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from avalanche.benchmarks.classic import SplitMNIST\n",
        "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, \\\n",
        "    loss_metrics, timing_metrics, cpu_usage_metrics, confusion_matrix_metrics, disk_usage_metrics\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "from avalanche.training.strategies import Naive\n",
        "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader\n",
        "from avalanche.training.storage_policy import ReservoirSamplingBuffer\n",
        "from types import SimpleNamespace\n",
        "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
        "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
        "from avalanche.training.plugins import StrategyPlugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R33HzLiWp6Ic"
      },
      "source": [
        "## A comprehensive example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzS_8A5TqAgi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3922ac9ae2f4457a9dfc75b6e6dbfb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d23681ef255f41b0af7922fa794da80c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4301fb5c7ac48a3ae474b21e609fb16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab28a2655e004b5a8fe5866959f4313a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting experiment...\n",
            "Start of experience:  0\n",
            "Current Classes:  [8, 9]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 0 (Task 0) from train stream --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/avalanche/training/plugins/evaluation.py:84: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
            "  \"No benchmark provided to the evaluation plugin. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:03<00:00,  7.42it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55536.4629\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55536.4629\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2134\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.4104\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0187\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.2358\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6629\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9167\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.09it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 97.1364\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55541.0479\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3513\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9460\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.36it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 96.5331\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55541.4033\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 5.0745\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.90it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 96.5591\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55541.7588\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.7913\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.13it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 98.3635\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55542.1143\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 5.1002\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 33.22it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 97.5704\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55542.4697\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.3829\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 698, 282],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 980, 155],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 811, 221],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 885, 125],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  46, 936],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 683, 209],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 546, 412],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  59, 969],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 906,  68],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  39, 970]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55542.4697\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.9402\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1876\n",
            "Start of experience:  1\n",
            "Current Classes:  [0, 3]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 1 (Task 0) from train stream --\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.63it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55555.7471\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55555.7471\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7890\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.3477\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0053\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.8992\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5430\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9259\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.90it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 98.9710\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55560.3320\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9460\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6450\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.57it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 98.9385\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55560.7549\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2300\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9824\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.19it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 95.9209\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55561.1104\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.4834\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 34.57it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 96.2455\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55561.4658\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.8591\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 34.61it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 96.6974\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55561.8213\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.0984\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[ 953,    0,    0,   27,    0,    0,    0,    0,    0,    0],\n",
            "        [   0,    0,    0, 1135,    0,    0,    0,    0,    0,    0],\n",
            "        [ 166,    0,    0,  866,    0,    0,    0,    0,    0,    0],\n",
            "        [   8,    0,    0, 1002,    0,    0,    0,    0,    0,    0],\n",
            "        [ 230,    0,    0,  752,    0,    0,    0,    0,    0,    0],\n",
            "        [ 207,    0,    0,  685,    0,    0,    0,    0,    0,    0],\n",
            "        [ 456,    0,    0,  502,    0,    0,    0,    0,    0,    0],\n",
            "        [ 182,    0,    0,  846,    0,    0,    0,    0,    0,    0],\n",
            "        [ 107,    0,    0,  867,    0,    0,    0,    0,    0,    0],\n",
            "        [ 145,    0,    0,  864,    0,    0,    0,    0,    0,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55561.8213\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.4615\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.9460\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1955\n",
            "Start of experience:  2\n",
            "Current Classes:  [6, 7]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 2 (Task 0) from train stream --\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.61it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55579.1963\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55579.1963\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0401\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.4385\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0046\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.9033\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4663\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9891\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.82it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 93.7090\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55579.7812\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9460\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.0389\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.07it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 94.9609\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55580.2041\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.8407\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.7044\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1417\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.65it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 97.1506\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55580.6270\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3646\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9879\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 32.74it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 95.1102\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55580.9824\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.7396\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 32.90it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 99.0728\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55581.3379\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.5576\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[ 202,    0,    0,    0,    0,    0,  715,   63,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  532,  603,    0,    0],\n",
            "        [   0,    0,    0,    1,    0,    0,  844,  187,    0,    0],\n",
            "        [   0,    0,    0,   80,    0,    0,  445,  485,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  364,  618,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  571,  321,    0,    0],\n",
            "        [   1,    0,    0,    0,    0,    0,  951,    6,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,   17, 1011,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  514,  460,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,   78,  931,    0,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55581.3379\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.4868\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.8934\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2244\n",
            "Start of experience:  3\n",
            "Current Classes:  [2, 5]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 3 (Task 0) from train stream --\n",
            "100%|██████████| 23/23 [00:02<00:00,  8.16it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55594.7129\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55594.7129\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2599\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 1.0285\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0054\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.8168\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2783\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8417\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.29it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 98.7804\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55599.2979\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9460\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.8417\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 32.53it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 99.5918\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55599.7207\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.9422\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1893\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0402\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.11it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 99.0851\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55600.1436\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.5891\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.4655\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3988\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 34.34it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 95.5144\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55600.5664\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9197\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8732\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 31.97it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 92.8602\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55600.9219\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.2216\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[  80,    0,  761,    0,    0,  138,    0,    1,    0,    0],\n",
            "        [   0,    0,  953,    0,    0,  182,    0,    0,    0,    0],\n",
            "        [   0,    0, 1026,    0,    0,    3,    1,    2,    0,    0],\n",
            "        [   0,    0,  799,    0,    0,  197,    0,   14,    0,    0],\n",
            "        [   0,    0,  766,    0,    0,  199,    0,   17,    0,    0],\n",
            "        [   0,    0,  234,    0,    0,  654,    0,    4,    0,    0],\n",
            "        [   0,    0,  939,    0,    0,   19,    0,    0,    0,    0],\n",
            "        [   0,    0,  210,    0,    0,   26,    0,  792,    0,    0],\n",
            "        [   0,    0,  808,    0,    0,  160,    0,    6,    0,    0],\n",
            "        [   0,    0,  528,    0,    0,  235,    0,  246,    0,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55600.9219\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.1492\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.8258\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2552\n",
            "Start of experience:  4\n",
            "Current Classes:  [1, 4]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 4 (Task 0) from train stream --\n",
            "100%|██████████| 26/26 [00:03<00:00,  8.27it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55618.2969\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55618.2969\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9867\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.6203\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0047\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.1416\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4263\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9762\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.39it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 97.4487\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55618.8818\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9460\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.8442\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.17it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 97.3740\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55619.3047\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.8236\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1273\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1588\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.81it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 93.8625\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55619.7275\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.8525\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.9454\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1354\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.23it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 96.6959\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55620.1504\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp003 = 0.5769\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.6908\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2963\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 32.99it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 97.3922\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55620.5732\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5641\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9792\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[ 313,   17,  300,    0,  245,  105,    0,    0,    0,    0],\n",
            "        [   0, 1135,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   0,  427,  403,    0,  200,    1,    0,    1,    0,    0],\n",
            "        [   0,  729,   98,    3,  135,   40,    0,    5,    0,    0],\n",
            "        [   0,   43,    1,    0,  938,    0,    0,    0,    0,    0],\n",
            "        [   1,  349,   30,    0,  342,  167,    0,    3,    0,    0],\n",
            "        [   1,  151,   29,    0,  775,    2,    0,    0,    0,    0],\n",
            "        [   0,  197,    9,    0,  553,    0,    0,  269,    0,    0],\n",
            "        [   0,  550,    2,    0,  420,    2,    0,    0,    0,    0],\n",
            "        [   0,   81,    5,    0,  923,    0,    0,    0,    0,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55620.5732\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.8184\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.7998\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3228\n"
          ]
        }
      ],
      "source": [
        "scenario = SplitMNIST(n_experiences=5)\n",
        "\n",
        "# MODEL CREATION\n",
        "model = SimpleMLP(num_classes=scenario.n_classes)\n",
        "\n",
        "# DEFINE THE EVALUATION PLUGIN and LOGGERS\n",
        "# The evaluation plugin manages the metrics computation.\n",
        "# It takes as argument a list of metrics, collectes their results and returns\n",
        "# them to the strategy it is attached to.\n",
        "\n",
        "# log to Tensorboard\n",
        "tb_logger = TensorboardLogger()\n",
        "\n",
        "# log to text file\n",
        "text_logger = TextLogger(open('log.txt', 'a'))\n",
        "\n",
        "# print to stdout\n",
        "interactive_logger = InteractiveLogger()\n",
        "\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    timing_metrics(epoch=True, epoch_running=True),\n",
        "    forgetting_metrics(experience=True, stream=True),\n",
        "    cpu_usage_metrics(experience=True),\n",
        "    confusion_matrix_metrics(num_classes=scenario.n_classes, save_image=False,\n",
        "                             stream=True),\n",
        "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loggers=[interactive_logger, text_logger, tb_logger]\n",
        ")\n",
        "\n",
        "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
        "cl_strategy = Naive(\n",
        "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
        "    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,\n",
        "    evaluator=eval_plugin)\n",
        "\n",
        "# TRAINING LOOP\n",
        "print('Starting experiment...')\n",
        "results = []\n",
        "for experience in scenario.train_stream:\n",
        "    print(\"Start of experience: \", experience.current_experience)\n",
        "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
        "\n",
        "    # train returns a dictionary which contains all the metric values\n",
        "    res = cl_strategy.train(experience)\n",
        "    print('Training completed')\n",
        "\n",
        "    print('Computing accuracy on the whole test set')\n",
        "    # test also returns a dictionary which contains all the metric values\n",
        "    results.append(cl_strategy.eval(scenario.test_stream))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22JZv6zTqK2b"
      },
      "source": [
        "## Dataloading, Memory Buffers, and Replay\n",
        "\n",
        "Avalanche provides several components that help you to balance data loading and implement rehearsal strategies.\n",
        "\n",
        "**Dataloaders** are used to provide balancing between groups (e.g. tasks/classes/experiences). This is especially useful when you have unbalanced data.\n",
        "\n",
        "**Buffers** are used to store data from the previous experiences. They are dynamic datasets with a fixed maximum size, and they can be updated with new data continuously.\n",
        "\n",
        "Finally, **Replay** strategies implement rehearsal by using Avalanche's plugin system. Most rehearsal strategies use a custom dataloader to balance the buffer with the current experience and a buffer that is updated for each experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxR7kLyYqK2g"
      },
      "source": [
        "### Dataloaders\n",
        "Avalanche dataloaders are simple iterators, located under `avalanche.benchmarks.utils.data_loader`. Their interface is equivalent to pytorch's dataloaders. For example, `GroupBalancedDataLoader` takes a sequence of datasets and iterates over them by providing balanced mini-batches, where the number of samples is split equally among groups. Internally, it instantiate a `DataLoader` for each separate group. More specialized dataloaders exist such as `TaskBalancedDataLoader`.\n",
        "\n",
        "All the dataloaders accept keyword arguments (`**kwargs`) that are passed directly to the dataloaders for each group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6VKo17IqK2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]\n"
          ]
        }
      ],
      "source": [
        "benchmark = SplitMNIST(5, return_task_id=True)\n",
        "\n",
        "dl = GroupBalancedDataLoader([exp.dataset for exp in benchmark.train_stream], batch_size=4)\n",
        "for x, y, t in dl:\n",
        "    print(t.tolist())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDBr8nrrqK2l"
      },
      "source": [
        "### Memory Buffers\n",
        "Memory buffers store data up to a maximum capacity, and they implement policies to select which data to store and which the to remove when the buffer is full. They are available in the module `avalanche.training.storage_policy`. The base class is the `ExemplarsBuffer`, which implements two methods:\n",
        "- `update(strategy)` - given the strategy's state it updates the buffer (using the data in `strategy.experience.dataset`).\n",
        "- `resize(strategy, new_size)` - updates the maximum size and updates the buffer accordingly.\n",
        "\n",
        "The data can be access using the attribute `buffer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VievPzGAqK2n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max buffer size: 30, current size: 0\n"
          ]
        }
      ],
      "source": [
        "benchmark = SplitMNIST(5, return_task_id=False)\n",
        "storage_p = ReservoirSamplingBuffer(max_size=30)\n",
        "\n",
        "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x6SPZKwqK2o"
      },
      "source": [
        "At first, the buffer is empty. We can update it with data from a new experience.\n",
        "\n",
        "Notice that we use a `SimpleNamespace` because we want to use the buffer standalone, without instantiating an Avalanche strategy. Reservoir sampling requires only the `experience` from the strategy's state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzoX7ApzqK2p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 7, 0, 0, 0, 7, 0, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 0, 0, 0, 7, 0, 7, 7, 7, 7, 0, 0, 0, 0]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 7, 0, 0, 0, 7, 6, 0, 1, 6, 1, 7, 1, 7, 1, 1, 6, 0, 7, 0, 1, 1, 0, 7, 6, 6, 7, 6, 6, 1]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 4, 4, 7, 0, 4, 4, 0, 4, 4, 0, 2, 7, 6, 2, 0, 1, 6, 2, 1, 7, 1, 4, 7, 2, 2, 1, 2, 1, 6]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 4, 4, 7, 0, 4, 4, 0, 4, 4, 9, 9, 0, 2, 7, 6, 2, 0, 1, 6, 2, 1, 7, 1, 4, 9, 7, 2, 2, 5]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 8, 3, 4, 4, 3, 7, 0, 4, 4, 0, 4, 4, 8, 9, 8, 9, 0, 2, 7, 6, 2, 0, 1, 6, 2, 8, 1, 7, 3]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
        "    storage_p.update(strategy_state)\n",
        "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
        "    print(f\"class targets: {storage_p.buffer.targets}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehtHBo9iqK2r"
      },
      "source": [
        "Notice after each update some samples are substituted with new data. Reservoir sampling select these samples randomly.\n",
        "\n",
        "Avalanche offers many more storage policies. For example, `ParametricBuffer` is a buffer split into several groups according to the `groupby` parameters (`None`, 'class', 'task', 'experience'), and according to an optional `ExemplarsSelectionStrategy` (random selection is the default choice)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Gh25nxqK2t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max buffer size: 30, current size: 0\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 0, 0, 0, 7, 7, 7, 1, 1, 1, 1, 6, 6, 6, 6, 4, 4, 4, 4, 2, 2, 2, 2, 5, 5, 5, 5, 9, 9, 9]\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: [0, 0, 0, 7, 7, 7, 1, 1, 1, 6, 6, 6, 4, 4, 4, 2, 2, 2, 5, 5, 5, 9, 9, 9, 3, 3, 3, 8, 8, 8]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "storage_p = ParametricBuffer(\n",
        "    max_size=30,\n",
        "    groupby='class',\n",
        "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
        ")\n",
        "\n",
        "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
        "for i in range(5):\n",
        "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
        "    storage_p.update(strategy_state)\n",
        "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
        "    print(f\"class targets: {storage_p.buffer.targets}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfPvkBeaqK2w"
      },
      "source": [
        "The advantage of using grouping buffers is that you get a balanced rehearsal buffer. You can even access the groups separately with the `buffer_groups` attribute. Combined with balanced dataloaders, you can ensure that the mini-batches stay balanced during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INhxgBToqK2x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(group 0) -> size 3\n",
            "(group 7) -> size 3\n",
            "(group 1) -> size 3\n",
            "(group 6) -> size 3\n",
            "(group 4) -> size 3\n",
            "(group 2) -> size 3\n",
            "(group 5) -> size 3\n",
            "(group 9) -> size 3\n",
            "(group 3) -> size 3\n",
            "(group 8) -> size 3\n"
          ]
        }
      ],
      "source": [
        "for k, v in storage_p.buffer_groups.items():\n",
        "    print(f\"(group {k}) -> size {len(v.buffer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lmtS6lrqK2y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 7, 1, 6, 4, 2, 5, 9, 3, 8]\n"
          ]
        }
      ],
      "source": [
        "datas = [v.buffer for v in storage_p.buffer_groups.values()]\n",
        "dl = GroupBalancedDataLoader(datas)\n",
        "\n",
        "for x, y, t in dl:\n",
        "    print(y.tolist())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RGMxaRBqK2y"
      },
      "source": [
        "### Replay Plugins\n",
        "\n",
        "Avalanche's strategy plugins can be used to update the rehearsal buffer and set the dataloader. This allows to easily implement replay strategies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ3KQgPSq-Fy"
      },
      "outputs": [],
      "source": [
        "from avalanche.training import Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCY_t3qWqK2z"
      },
      "outputs": [],
      "source": [
        "class CustomReplay(StrategyPlugin):\n",
        "    def __init__(self, storage_policy):\n",
        "        super().__init__()\n",
        "        self.storage_policy = storage_policy\n",
        "\n",
        "    def before_training_exp(self, strategy,\n",
        "                            num_workers: int = 0, shuffle: bool = True,\n",
        "                            **kwargs):\n",
        "        \"\"\" Here we set the dataloader. \"\"\"\n",
        "        if len(self.storage_policy.buffer) == 0:\n",
        "            # first experience. We don't use the buffer, no need to change\n",
        "            # the dataloader.\n",
        "            return\n",
        "\n",
        "        # replay dataloader samples mini-batches from the memory and current\n",
        "        # data separately and combines them together.\n",
        "        print(\"Override the dataloader.\")\n",
        "        strategy.dataloader = ReplayDataLoader(\n",
        "            strategy.adapted_dataset,\n",
        "            self.storage_policy.buffer,\n",
        "            oversample_small_tasks=True,\n",
        "            num_workers=num_workers,\n",
        "            batch_size=strategy.train_mb_size,\n",
        "            shuffle=shuffle)\n",
        "\n",
        "    def after_training_exp(self, strategy: \"BaseStrategy\", **kwargs):\n",
        "        \"\"\" We update the buffer after the experience.\n",
        "            You can use a different callback to update the buffer in a different place\n",
        "        \"\"\"\n",
        "        print(\"Buffer update.\")\n",
        "        self.storage_policy.update(strategy, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWCwEFyqK20"
      },
      "source": [
        "And of course, we can use the plugin to train our continual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p96kLvWqK20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting experiment...\n",
            "Start of experience  0\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 0 (Task 0) from train stream --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/avalanche/training/plugins/evaluation.py:84: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
            "  \"No benchmark provided to the evaluation plugin. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:03<00:00, 30.17it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 37.94it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9865\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 36.46it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.71it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.72it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 37.04it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1898\n",
            "Start of experience  1\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "-- Starting training on experience 1 (Task 0) from train stream --\n",
            "100%|██████████| 254/254 [00:09<00:00, 27.97it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 37.32it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9636\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 37.23it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9962\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 36.32it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.76it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 36.65it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3961\n",
            "Start of experience  2\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "-- Starting training on experience 2 (Task 0) from train stream --\n",
            "100%|██████████| 240/240 [00:08<00:00, 28.11it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.21it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8971\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 36.54it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9868\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 36.04it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9885\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 36.35it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 36.76it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5782\n",
            "Start of experience  3\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "-- Starting training on experience 3 (Task 0) from train stream --\n",
            "100%|██████████| 238/238 [00:08<00:00, 28.66it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.57it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8960\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 38.30it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9702\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 39.00it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.8705\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.11it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9797\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 38.46it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7437\n",
            "Start of experience  4\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "-- Starting training on experience 4 (Task 0) from train stream --\n",
            "100%|██████████| 243/243 [00:08<00:00, 28.22it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.18it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8446\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 38.21it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9414\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 36.86it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.8956\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 37.85it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8902\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 37.72it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9730\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9099\n"
          ]
        }
      ],
      "source": [
        "scenario = SplitMNIST(5)\n",
        "model = SimpleMLP(num_classes=scenario.n_classes)\n",
        "storage_p = ParametricBuffer(\n",
        "    max_size=500,\n",
        "    groupby='class',\n",
        "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
        ")\n",
        "\n",
        "# choose some metrics and evaluation method\n",
        "interactive_logger = InteractiveLogger()\n",
        "\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(experience=True, stream=True),\n",
        "    loggers=[interactive_logger])\n",
        "\n",
        "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
        "cl_strategy = Naive(model, torch.optim.Adam(model.parameters(), lr=0.001),\n",
        "                    CrossEntropyLoss(),\n",
        "                    train_mb_size=100, train_epochs=1, eval_mb_size=100,\n",
        "                    plugins=[CustomReplay(storage_p)],\n",
        "                    evaluator=eval_plugin\n",
        "                    )\n",
        "\n",
        "# TRAINING LOOP\n",
        "print('Starting experiment...')\n",
        "results = []\n",
        "for experience in scenario.train_stream:\n",
        "    print(\"Start of experience \", experience.current_experience)\n",
        "    cl_strategy.train(experience)\n",
        "    print('Training completed')\n",
        "\n",
        "    print('Computing accuracy on the whole test set')\n",
        "    results.append(cl_strategy.eval(scenario.test_stream))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "T860884_Avalanche_Visual_Incremental_Learning.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
