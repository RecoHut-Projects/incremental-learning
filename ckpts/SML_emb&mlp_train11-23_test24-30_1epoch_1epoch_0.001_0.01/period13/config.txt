train_config: {'method': 'SML_by_period', 'dir_name': 'SML_emb&mlp_train11-23_test24-30_1epoch_1epoch_0.001_0.01', 'pretrain_model': 'pretrain_train1-10_test11_10epoch_0.001', 'start_date': 20140901, 'end_date': 20141231, 'num_periods': 31, 'train_start_period': 11, 'test_start_period': 24, 'cur_period': 13, 'next_period': 14, 'cur_set_size': 54365, 'next_set_size': 54365, 'period_alias': 'period13', 'restored_ckpt_mode': 'best auc', 'restored_ckpt': 'ckpts/SML_emb&mlp_train11-23_test24-30_1epoch_1epoch_0.001_0.01/period12/Epoch1_TestAUC0.8669_TestLOGLOSS0.4693.ckpt', 'transfer_emb': True, 'emb_n1': 10, 'emb_n2': 5, 'emb_l1': 20, 'transfer_mlp': True, 'mlp_n1': 5, 'mlp_n2': 3, 'mlp_l1_dict': {'fcn1/kernel': 40, 'fcn1/bias': 20, 'fcn2/kernel': 20, 'fcn2/bias': 10, 'fcn3/kernel': 10, 'fcn3/bias': 1}, 'transfer_optimizer': 'adam', 'transfer_lr': 0.001, 'transfer_bs': 256, 'transfer_num_epochs': 1, 'test_stop_train': False, 'base_optimizer': 'adam', 'base_lr': 0.01, 'base_bs': 256, 'base_num_epochs': 1, 'shuffle': True}

EmbMLPnocate_hyperparams: {'num_users': 17126, 'num_items': 24785, 'user_embed_dim': 8, 'item_embed_dim': 8, 'layers': [24, 12, 6, 1]}
